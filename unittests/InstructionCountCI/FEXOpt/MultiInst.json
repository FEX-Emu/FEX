{
  "Features": {
    "Bitness": 64,
    "EnabledHostFeatures": [
      "FLAGM",
      "FLAGM2",
      "FRINTTS"
    ],
    "DisabledHostFeatures": [
      "SVE128",
      "SVE256",
      "RPRES",
      "AFP"
    ]
  },
  "Comment": [
    "These are instruction combinations that could be more optimal if FEX optimized for them"
  ],
  "Instructions": {
    "cpuid constant": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 11,
      "Comment": [
        "CPUID function call with constant function id"
      ],
      "x86Insts": [
        "mov rax, 0",
        "cpuid"
      ],
      "ExpectedArm64ASM": [
        "mov w4, #0x0",
        "isb",
        "mov w20, #0x16",
        "mov w6, #0x6547",
        "movk w6, #0x756e, lsl #16",
        "mov w21, #0x746e",
        "movk w21, #0x6c65, lsl #16",
        "mov w5, #0x6e69",
        "movk w5, #0x4965, lsl #16",
        "mov x7, x21",
        "mov x4, x20"
      ]
    },
    "xgetbv constant": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 3,
      "Comment": [
        "XGETBV function call with constant function id"
      ],
      "x86Insts": [
        "mov rcx, 0",
        "xgetbv"
      ],
      "ExpectedArm64ASM": [
        "mov w7, #0x0",
        "mov w4, #0x7",
        "mov w5, #0x0"
      ]
    },
    "signed div narrow": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 5,
      "Comment": [
        "div narrowing with known smaller sources",
        "dividend in rdx:rax"
      ],
      "x86Insts": [
        "cqo",
        "idiv rcx"
      ],
      "ExpectedArm64ASM": [
        "asr x5, x4, #63",
        "sdiv x20, x4, x7",
        "msub x22, x20, x7, x4",
        "mov x5, x22",
        "mov x4, x20"
      ]
    },
    "unsigned div narrow": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 5,
      "Comment": [
        "div narrowing with known smaller sources",
        "dividend in rdx:rax"
      ],
      "x86Insts": [
        "mov rdx, 0",
        "div rcx"
      ],
      "ExpectedArm64ASM": [
        "mov w5, #0x0",
        "udiv x20, x4, x7",
        "msub x22, x20, x7, x4",
        "mov x5, x22",
        "mov x4, x20"
      ]
    },
    "unsigned div narrow with flags": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "div narrowing with known smaller sources",
        "dividend in rdx:rax"
      ],
      "x86Insts": [
        "xor rdx, rdx",
        "div rcx"
      ],
      "ExpectedArm64ASM": [
        "subs w26, w5, w5",
        "mov w5, #0x0",
        "udiv x20, x4, x7",
        "msub x22, x20, x7, x4",
        "mov x5, x22",
        "mov x4, x20"
      ]
    },
    "signed div narrow 32-bit": {
      "x86InstructionCount": 3,
      "ExpectedInstructionCount": 10,
      "x86Insts": [
        "mov    eax, edi",
        "cdq",
        "idiv    esi"
      ],
      "ExpectedArm64ASM": [
        "mov w4, w11",
        "asr w5, w4, #31",
        "mov w20, w10",
        "mov x0, x4",
        "bfi x0, x5, #32, #32",
        "sxtw x1, w20",
        "sdiv x22, x0, x1",
        "msub x21, x22, x1, x0",
        "mov w4, w22",
        "mov w5, w21"
      ]
    },
    "unsigned div narrow 32-bit": {
      "x86InstructionCount": 3,
      "ExpectedInstructionCount": 7,
      "x86Insts": [
        "mov    eax, edi",
        "xor    edx, edx",
        "div    esi"
      ],
      "ExpectedArm64ASM": [
        "mov w4, w11",
        "subs w26, w5, w5",
        "mov w5, #0x0",
        "udiv w20, w4, w10",
        "msub w22, w20, w10, w4",
        "mov w4, w20",
        "mov w5, w22"
      ]
    },
    "push ax, bx": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 2,
      "Comment": [
        "Mergable 16-bit pushes. May or may not be an optimization."
      ],
      "x86Insts": [
        "push ax",
        "push bx"
      ],
      "ExpectedArm64ASM": [
        "strh w4, [x8, #-2]!",
        "strh w6, [x8, #-2]!"
      ]
    },
    "push rax, rbx": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 1,
      "Comment": [
        "Mergable 64-bit pushes"
      ],
      "x86Insts": [
        "push rax",
        "push rbx"
      ],
      "ExpectedArm64ASM": [
        "stp x6, x4, [x8, #-16]!"
      ]
    },
    "adds xmm0, xmm1, xmm2": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 4,
      "Comment": [
        "Redundant scalar adds that can get eliminated without AFP."
      ],
      "x86Insts": [
        "addss xmm0, xmm1",
        "addss xmm0, xmm2"
      ],
      "ExpectedArm64ASM": [
        "fadd s0, s16, s17",
        "mov v16.s[0], v0.s[0]",
        "fadd s0, s16, s18",
        "mov v16.s[0], v0.s[0]"
      ]
    },
    "positive movsb": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldrb w21, [x10]",
        "strb w21, [x11]",
        "add x10, x10, #0x1 (1)",
        "add x11, x11, #0x1 (1)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive movsw": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldrh w21, [x10]",
        "strh w21, [x11]",
        "add x10, x10, #0x2 (2)",
        "add x11, x11, #0x2 (2)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive movsd": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldr w21, [x10]",
        "str w21, [x11]",
        "add x10, x10, #0x4 (4)",
        "add x11, x11, #0x4 (4)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive movsq": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldr x21, [x10]",
        "str x21, [x11]",
        "add x10, x10, #0x8 (8)",
        "add x11, x11, #0x8 (8)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsb": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldrb w21, [x10]",
        "strb w21, [x11]",
        "sub x10, x10, #0x1 (1)",
        "sub x11, x11, #0x1 (1)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsw": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldrh w21, [x10]",
        "strh w21, [x11]",
        "sub x10, x10, #0x2 (2)",
        "sub x11, x11, #0x2 (2)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsd": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldr w21, [x10]",
        "str w21, [x11]",
        "sub x10, x10, #0x4 (4)",
        "sub x11, x11, #0x4 (4)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsq": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldr x21, [x10]",
        "str x21, [x11]",
        "sub x10, x10, #0x8 (8)",
        "sub x11, x11, #0x8 (8)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive rep movsb": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 43,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x14",
        "ldrb w3, [x2], #1",
        "strb w3, [x1], #1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "add x22, x0, x2",
        "add x21, x1, x2",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "positive rep movsw": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 43,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x14",
        "ldrh w3, [x2], #2",
        "strh w3, [x1], #2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "add x22, x0, x2, lsl #1",
        "add x21, x1, x2, lsl #1",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "positive rep movsd": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 43,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x14",
        "ldr w3, [x2], #4",
        "str w3, [x1], #4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "add x22, x0, x2, lsl #2",
        "add x21, x1, x2, lsl #2",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "positive rep movsq": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 43,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x14",
        "ldr x3, [x2], #8",
        "str x3, [x1], #8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "add x22, x0, x2, lsl #3",
        "add x21, x1, x2, lsl #3",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "negative rep movsb": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1f (31)",
        "sub x2, x2, #0x1f (31)",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1f (31)",
        "add x2, x2, #0x1f (31)",
        "ldrb w3, [x2], #-1",
        "strb w3, [x1], #-1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "sub x22, x0, x2",
        "sub x21, x1, x2",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "negative rep movsw": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1e (30)",
        "sub x2, x2, #0x1e (30)",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1e (30)",
        "add x2, x2, #0x1e (30)",
        "ldrh w3, [x2], #-2",
        "strh w3, [x1], #-2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "sub x22, x0, x2, lsl #1",
        "sub x21, x1, x2, lsl #1",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "negative rep movsd": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1c (28)",
        "sub x2, x2, #0x1c (28)",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1c (28)",
        "add x2, x2, #0x1c (28)",
        "ldr w3, [x2], #-4",
        "str w3, [x1], #-4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "sub x22, x0, x2, lsl #2",
        "sub x21, x1, x2, lsl #2",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "negative rep movsq": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x7",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x18 (24)",
        "sub x2, x2, #0x18 (24)",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x18 (24)",
        "add x2, x2, #0x18 (24)",
        "ldr x3, [x2], #-8",
        "str x3, [x1], #-8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x7",
        "sub x22, x0, x2, lsl #3",
        "sub x21, x1, x2, lsl #3",
        "mov w7, #0x0",
        "strb w20, [x28, #986]",
        "mov x11, x22",
        "mov x10, x21"
      ]
    },
    "positive rep stosb": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 29,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "uxtb w21, w4",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.16b, w21",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x10",
        "strb w21, [x1], #1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x7",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "positive rep stosw": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 29,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "uxth w21, w4",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.8h, w21",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x10",
        "strh w21, [x1], #2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x7, lsl #1",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "positive rep stosd": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 29,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "mov w21, w4",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.4s, w21",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x10",
        "str w21, [x1], #4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x7, lsl #2",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "positive rep stosq": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 28,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.2d, x4",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x10",
        "str x4, [x1], #8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x7, lsl #3",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosb": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "uxtb w21, w4",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1f (31)",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.16b, w21",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1f (31)",
        "strb w21, [x1], #-1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x7",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosw": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "uxth w21, w4",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1e (30)",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.8h, w21",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1e (30)",
        "strh w21, [x1], #-2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x7, lsl #1",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosd": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov w21, w4",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1c (28)",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.4s, w21",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1c (28)",
        "str w21, [x1], #-4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x7, lsl #2",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosq": {
      "x86InstructionCount": 2,
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x7",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x18 (24)",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.2d, x4",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x18 (24)",
        "str x4, [x1], #-8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x7, lsl #3",
        "mov w7, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "Sekiro spill block": {
      "x86InstructionCount": 119,
      "ExpectedInstructionCount": 115,
      "Comment": [
        "This block of code came from the settings screen when it loaded",
        "It was originally at RIP: 0x14232cca0 and has been deobfuscated"
      ],
      "x86Insts": [
        "mov    QWORD [rsp+0x8],rcx",
        "push   rbx",
        "push   rbp",
        "push   rsi",
        "push   rdi",
        "push   r12",
        "push   r13",
        "push   r14",
        "push   r15",
        "sub    rsp,0x18",
        "mov    ecx,dword [rdx+0x24]",
        "mov    esi,dword [rdx]",
        "mov    ebp,dword [rdx+0x4]",
        "mov    r14d,dword [rdx+0x8]",
        "mov    r15d,dword [rdx+0xc]",
        "mov    r12d,dword [rdx+0x10]",
        "mov    r13d,dword [rdx+0x14]",
        "mov    r11d,dword [rdx+0x18]",
        "mov    ebx,dword [rdx+0x1c]",
        "mov    edi,dword [rdx+0x20]",
        "imul   eax,ecx,0x13",
        "mov    dword [rsp+0x68],ecx",
        "add    eax,0x1000000",
        "shr    eax,0x19",
        "add    eax,esi",
        "sar    eax,0x1a",
        "add    eax,ebp",
        "sar    eax,0x19",
        "add    eax,r14d",
        "sar    eax,0x1a",
        "add    eax,r15d",
        "sar    eax,0x19",
        "add    eax,r12d",
        "sar    eax,0x1a",
        "add    eax,r13d",
        "sar    eax,0x19",
        "add    eax,r11d",
        "sar    eax,0x1a",
        "add    eax,ebx",
        "sar    eax,0x19",
        "add    eax,edi",
        "sar    eax,0x1a",
        "add    eax,ecx",
        "sar    eax,0x19",
        "imul   eax,eax,0x13",
        "add    esi,eax",
        "mov    eax,esi",
        "sar    eax,0x1a",
        "add    ebp,eax",
        "shl    eax,0x1a",
        "sub    esi,eax",
        "mov    ecx,ebp",
        "mov    rax,qword [rsp+0x60]",
        "sar    ecx,0x19",
        "add    r14d,ecx",
        "shl    ecx,0x19",
        "mov    edx,r14d",
        "sub    ebp,ecx",
        "sar    edx,0x1a",
        "add    r15d,edx",
        "mov    dword [rax],esi",
        "mov    r8d,r15d",
        "shl    edx,0x1a",
        "sar    r8d,0x19",
        "sub    r14d,edx",
        "add    r12d,r8d",
        "mov    dword [rax+0x4],ebp",
        "mov    r9d,r12d",
        "shl    r8d,0x19",
        "sar    r9d,0x1a",
        "sub    r15d,r8d",
        "add    r13d,r9d",
        "mov    dword [rax+0x8],r14d",
        "shl    r9d,0x1a",
        "mov    r10d,r13d",
        "sar    r10d,0x19",
        "sub    r12d,r9d",
        "add    r11d,r10d",
        "mov    dword [rax+0xc],r15d",
        "mov    dword [rsp+0x70],r11d",
        "mov    rsi,rax",
        "sar    r11d,0x1a",
        "add    ebx,r11d",
        "mov    dword [rax+0x10],r12d",
        "mov    dword [rsp+0x78],ebx",
        "sar    ebx,0x19",
        "add    edi,ebx",
        "mov    dword [rsp],edi",
        "sar    edi,0x1a",
        "add    dword [rsp+0x68],edi",
        "shl    r10d,0x19",
        "mov    ecx,dword [rsp+0x68]",
        "sub    r13d,r10d",
        "mov    dword [rax+0x14],r13d",
        "mov    eax,dword [rsp+0x70]",
        "shl    r11d,0x1a",
        "sub    eax,r11d",
        "shl    ebx,0x19",
        "mov    dword [rsi+0x18],eax",
        "mov    eax,dword [rsp+0x78]",
        "sub    eax,ebx",
        "shl    edi,0x1a",
        "mov    dword [rsi+0x1c],eax",
        "mov    eax,dword [rsp]",
        "sub    eax,edi",
        "mov    dword [rsi+0x20],eax",
        "mov    eax,ecx",
        "and    eax,0xfe000000",
        "sub    ecx,eax",
        "mov    dword [rsi+0x24],ecx",
        "add    rsp,0x18",
        "pop    r15",
        "pop    r14",
        "pop    r13",
        "pop    r12",
        "pop    rdi",
        "pop    rsi",
        "pop    rbp",
        "pop    rbx"
      ],
      "ExpectedArm64ASM": [
        "str x7, [x8, #8]",
        "stp x9, x6, [x8, #-16]!",
        "stp x11, x10, [x8, #-16]!",
        "stp x17, x16, [x8, #-16]!",
        "stp x29, x19, [x8, #-16]!",
        "sub x8, x8, #0x18 (24)",
        "ldr w7, [x5, #36]",
        "ldr w10, [x5]",
        "ldr w9, [x5, #4]",
        "ldr w19, [x5, #8]",
        "ldr w29, [x5, #12]",
        "ldr w16, [x5, #16]",
        "ldr w17, [x5, #20]",
        "ldr w15, [x5, #24]",
        "ldr w6, [x5, #28]",
        "ldr w11, [x5, #32]",
        "mov w20, #0x13",
        "mul w4, w7, w20",
        "str w7, [x8, #104]",
        "mov w21, #0x1000000",
        "add w4, w4, w21",
        "lsr w4, w4, #25",
        "add w4, w4, w10",
        "asr w4, w4, #26",
        "add w4, w4, w9",
        "asr w4, w4, #25",
        "add w4, w4, w19",
        "asr w4, w4, #26",
        "add w4, w4, w29",
        "asr w4, w4, #25",
        "add w4, w4, w16",
        "asr w4, w4, #26",
        "add w4, w4, w17",
        "asr w4, w4, #25",
        "add w4, w4, w15",
        "asr w4, w4, #26",
        "add w4, w4, w6",
        "asr w4, w4, #25",
        "add w4, w4, w11",
        "asr w4, w4, #26",
        "add w4, w4, w7",
        "asr w4, w4, #25",
        "mul w4, w4, w20",
        "add w10, w10, w4",
        "asr w4, w10, #26",
        "add w9, w9, w4",
        "lsl w4, w4, #26",
        "sub w10, w10, w4",
        "mov w7, w9",
        "ldr x4, [x8, #96]",
        "asr w7, w7, #25",
        "add w19, w19, w7",
        "lsl w7, w7, #25",
        "mov w5, w19",
        "sub w9, w9, w7",
        "asr w5, w5, #26",
        "add w29, w29, w5",
        "str w10, [x4]",
        "mov w12, w29",
        "lsl w5, w5, #26",
        "asr w12, w12, #25",
        "sub w19, w19, w5",
        "add w16, w16, w12",
        "str w9, [x4, #4]",
        "mov w13, w16",
        "lsl w12, w12, #25",
        "asr w13, w13, #26",
        "sub w29, w29, w12",
        "add w17, w17, w13",
        "str w19, [x4, #8]",
        "lsl w13, w13, #26",
        "asr w14, w17, #25",
        "sub w16, w16, w13",
        "add w15, w15, w14",
        "str w29, [x4, #12]",
        "str w15, [x8, #112]",
        "mov x10, x4",
        "asr w15, w15, #26",
        "add w6, w6, w15",
        "str w16, [x4, #16]",
        "str w6, [x8, #120]",
        "asr w6, w6, #25",
        "add w11, w11, w6",
        "str w11, [x8]",
        "asr w11, w11, #26",
        "ldr w20, [x8, #104]",
        "add w20, w20, w11",
        "str w20, [x8, #104]",
        "lsl w14, w14, #25",
        "ldr w7, [x8, #104]",
        "sub w17, w17, w14",
        "str w17, [x4, #20]",
        "ldr w4, [x8, #112]",
        "lsl w15, w15, #26",
        "sub w4, w4, w15",
        "lsl w6, w6, #25",
        "str w4, [x10, #24]",
        "ldr w4, [x8, #120]",
        "sub w4, w4, w6",
        "lsl w11, w11, #26",
        "str w4, [x10, #28]",
        "ldr w4, [x8]",
        "sub w4, w4, w11",
        "str w4, [x10, #32]",
        "and w4, w7, #0xfe000000",
        "sub w7, w7, w4",
        "str w7, [x10, #36]",
        "mvn w27, w8",
        "adds x26, x8, #0x18 (24)",
        "mov x8, x26",
        "ldp x29, x19, [x8], #16",
        "ldp x17, x16, [x8], #16",
        "ldp x11, x10, [x8], #16",
        "ldp x9, x6, [x8], #16",
        "cfinv"
      ]
    },
    "Control - random block using cvtss2si 1": {
      "x86InstructionCount": 7,
      "ExpectedInstructionCount": 13,
      "x86Insts": [
        "mov    rcx,rdx",
        "cvttss2si rax,xmm1",
        "add    rax,rcx",
        "mov    qword [rsp],rax",
        "mulss  xmm0,dword [rbp]",
        "xor    ecx,ecx",
        "comiss xmm0,xmm2"
      ],
      "ExpectedArm64ASM": [
        "mov x7, x5",
        "frint64z s2, s17",
        "fcvtzs x4, s2",
        "add x4, x4, x7",
        "str x4, [x8]",
        "ldr s2, [x9]",
        "fmul s0, s16, s2",
        "mov v16.s[0], v0.s[0]",
        "mov w7, #0x0",
        "fcmp s16, s18",
        "cset x26, vc",
        "axflag",
        "mov x27, x7"
      ]
    },
    "Control - random block using cvtss2si 2": {
      "x86InstructionCount": 6,
      "ExpectedInstructionCount": 9,
      "x86Insts": [
        "movss  xmm1,dword [rbp+0x40]",
        "roundss xmm1,xmm1,0x1",
        "cvtss2si eax,xmm1",
        "mov    dword [r15+0xb4],eax",
        "mov    dword [rbp+0x48],0x3f800000",
        "test   r14,r14"
      ],
      "ExpectedArm64ASM": [
        "ldr s17, [x9, #64]",
        "frintm s0, s17",
        "mov v17.s[0], v0.s[0]",
        "frint32x s2, s17",
        "fcvtzs w4, s2",
        "str w4, [x29, #180]",
        "mov w20, #0x3f800000",
        "str w20, [x9, #72]",
        "subs x26, x19, #0x0 (0)"
      ]
    },
    "Long-lived ymm_high test": {
      "x86InstructionCount": 16,
      "ExpectedInstructionCount": 132,
      "Comment": [
        "Inspired from a Geekbench benchmark hammering this instruction",
        "Keeps a bunch of ymm_high values live that can get spilled in to spill-slots",
        "These can instead be spilled back in to the context without any stack usage",
        "Useful to ensure we aren't evicting cachelines unnnecessarily"
      ],
      "x86Insts": [
        "vpmaddwd ymm0, ymm1, ymm15",
        "vpmaddwd ymm1, ymm2, ymm14",
        "vpmaddwd ymm2, ymm3, ymm13",
        "vpmaddwd ymm3, ymm4, ymm12",
        "vpmaddwd ymm4, ymm5, ymm11",
        "vpmaddwd ymm5, ymm6, ymm10",
        "vpmaddwd ymm6, ymm7, ymm9",
        "vpmaddwd ymm7, ymm8, ymm8",
        "vpmaddwd ymm8, ymm9, ymm7",
        "vpmaddwd ymm9, ymm10, ymm6",
        "vpmaddwd ymm10, ymm11, ymm5",
        "vpmaddwd ymm11, ymm12, ymm4",
        "vpmaddwd ymm12, ymm13, ymm3",
        "vpmaddwd ymm13, ymm14, ymm2",
        "vpmaddwd ymm14, ymm15, ymm1",
        "vpmaddwd ymm15, ymm0, ymm0"
      ],
      "ExpectedArm64ASM": [
        "sub sp, sp, #0xa0 (160)",
        "ldr q2, [x28, #48]",
        "ldr q3, [x28, #272]",
        "smull v4.4s, v17.4h, v31.4h",
        "smull2 v5.4s, v17.8h, v31.8h",
        "addp v16.4s, v4.4s, v5.4s",
        "smull v4.4s, v2.4h, v3.4h",
        "smull2 v2.4s, v2.8h, v3.8h",
        "addp v2.4s, v4.4s, v2.4s",
        "ldr q4, [x28, #64]",
        "ldr q5, [x28, #256]",
        "smull v6.4s, v18.4h, v30.4h",
        "smull2 v7.4s, v18.8h, v30.8h",
        "addp v17.4s, v6.4s, v7.4s",
        "smull v6.4s, v4.4h, v5.4h",
        "smull2 v4.4s, v4.8h, v5.8h",
        "addp v4.4s, v6.4s, v4.4s",
        "ldr q6, [x28, #80]",
        "ldr q7, [x28, #240]",
        "smull v8.4s, v19.4h, v29.4h",
        "smull2 v9.4s, v19.8h, v29.8h",
        "addp v18.4s, v8.4s, v9.4s",
        "smull v8.4s, v6.4h, v7.4h",
        "smull2 v6.4s, v6.8h, v7.8h",
        "addp v6.4s, v8.4s, v6.4s",
        "ldr q8, [x28, #96]",
        "ldr q9, [x28, #224]",
        "smull v10.4s, v20.4h, v28.4h",
        "smull2 v11.4s, v20.8h, v28.8h",
        "addp v19.4s, v10.4s, v11.4s",
        "smull v10.4s, v8.4h, v9.4h",
        "smull2 v8.4s, v8.8h, v9.8h",
        "addp v8.4s, v10.4s, v8.4s",
        "ldr q10, [x28, #112]",
        "ldr q11, [x28, #208]",
        "smull v12.4s, v21.4h, v27.4h",
        "smull2 v13.4s, v21.8h, v27.8h",
        "addp v20.4s, v12.4s, v13.4s",
        "smull v12.4s, v10.4h, v11.4h",
        "smull2 v10.4s, v10.8h, v11.8h",
        "addp v10.4s, v12.4s, v10.4s",
        "ldr q12, [x28, #128]",
        "ldr q13, [x28, #192]",
        "smull v14.4s, v22.4h, v26.4h",
        "smull2 v15.4s, v22.8h, v26.8h",
        "addp v21.4s, v14.4s, v15.4s",
        "smull v14.4s, v12.4h, v13.4h",
        "smull2 v12.4s, v12.8h, v13.8h",
        "addp v12.4s, v14.4s, v12.4s",
        "ldr q14, [x28, #144]",
        "ldr q15, [x28, #176]",
        "str q2, [sp]",
        "smull v2.4s, v23.4h, v25.4h",
        "str q3, [sp, #32]",
        "smull2 v3.4s, v23.8h, v25.8h",
        "addp v22.4s, v2.4s, v3.4s",
        "smull v2.4s, v14.4h, v15.4h",
        "smull2 v3.4s, v14.8h, v15.8h",
        "addp v2.4s, v2.4s, v3.4s",
        "ldr q3, [x28, #160]",
        "smull v14.4s, v24.4h, v24.4h",
        "str q4, [sp, #64]",
        "smull2 v4.4s, v24.8h, v24.8h",
        "addp v23.4s, v14.4s, v4.4s",
        "smull v4.4s, v3.4h, v3.4h",
        "smull2 v3.4s, v3.8h, v3.8h",
        "addp v3.4s, v4.4s, v3.4s",
        "smull v4.4s, v25.4h, v23.4h",
        "smull2 v14.4s, v25.8h, v23.8h",
        "addp v24.4s, v4.4s, v14.4s",
        "smull v4.4s, v15.4h, v3.4h",
        "smull2 v14.4s, v15.8h, v3.8h",
        "addp v4.4s, v4.4s, v14.4s",
        "smull v14.4s, v26.4h, v22.4h",
        "smull2 v15.4s, v26.8h, v22.8h",
        "addp v25.4s, v14.4s, v15.4s",
        "smull v14.4s, v13.4h, v2.4h",
        "smull2 v13.4s, v13.8h, v2.8h",
        "addp v13.4s, v14.4s, v13.4s",
        "smull v14.4s, v27.4h, v21.4h",
        "smull2 v15.4s, v27.8h, v21.8h",
        "addp v26.4s, v14.4s, v15.4s",
        "smull v14.4s, v11.4h, v12.4h",
        "smull2 v11.4s, v11.8h, v12.8h",
        "addp v11.4s, v14.4s, v11.4s",
        "smull v14.4s, v28.4h, v20.4h",
        "smull2 v15.4s, v28.8h, v20.8h",
        "addp v27.4s, v14.4s, v15.4s",
        "smull v14.4s, v9.4h, v10.4h",
        "smull2 v9.4s, v9.8h, v10.8h",
        "addp v9.4s, v14.4s, v9.4s",
        "smull v14.4s, v29.4h, v19.4h",
        "smull2 v15.4s, v29.8h, v19.8h",
        "addp v28.4s, v14.4s, v15.4s",
        "smull v14.4s, v7.4h, v8.4h",
        "smull2 v7.4s, v7.8h, v8.8h",
        "addp v7.4s, v14.4s, v7.4s",
        "smull v14.4s, v30.4h, v18.4h",
        "smull2 v15.4s, v30.8h, v18.8h",
        "addp v29.4s, v14.4s, v15.4s",
        "smull v14.4s, v5.4h, v6.4h",
        "smull2 v5.4s, v5.8h, v6.8h",
        "addp v5.4s, v14.4s, v5.4s",
        "smull v14.4s, v31.4h, v17.4h",
        "smull2 v15.4s, v31.8h, v17.8h",
        "addp v30.4s, v14.4s, v15.4s",
        "ldr q14, [sp, #32]",
        "ldr q15, [sp, #64]",
        "str q6, [sp, #96]",
        "smull v6.4s, v14.4h, v15.4h",
        "smull2 v14.4s, v14.8h, v15.8h",
        "addp v6.4s, v6.4s, v14.4s",
        "smull v14.4s, v16.4h, v16.4h",
        "smull2 v15.4s, v16.8h, v16.8h",
        "addp v31.4s, v14.4s, v15.4s",
        "ldr q14, [sp]",
        "smull v15.4s, v14.4h, v14.4h",
        "str q8, [sp, #128]",
        "smull2 v8.4s, v14.8h, v14.8h",
        "addp v8.4s, v15.4s, v8.4s",
        "stp q6, q8, [x28, #256]",
        "stp q7, q5, [x28, #224]",
        "stp q11, q9, [x28, #192]",
        "stp q4, q13, [x28, #160]",
        "stp q2, q3, [x28, #128]",
        "stp q10, q12, [x28, #96]",
        "ldr q2, [sp, #96]",
        "ldr q3, [sp, #128]",
        "stp q2, q3, [x28, #64]",
        "ldr q2, [sp, #64]",
        "stp q14, q2, [x28, #32]",
        "add sp, sp, #0xa0 (160)"
      ]
    }
  }
}
