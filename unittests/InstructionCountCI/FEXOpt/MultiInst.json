{
  "Features": {
    "Bitness": 64,
    "EnabledHostFeatures": [],
    "DisabledHostFeatures": [
      "SVE128",
      "SVE256",
      "RPRES",
      "AFP"
    ]
  },
  "Comment": [
    "These are instruction combinations that could be more optimal if FEX optimized for them"
  ],
  "Instructions": {
    "push ax, bx": {
      "ExpectedInstructionCount": 2,
      "Comment": [
        "Mergable 16-bit pushes. May or may not be an optimization."
      ],
      "x86Insts": [
        "push ax",
        "push bx"
      ],
      "ExpectedArm64ASM": [
        "strh w4, [x8, #-2]!",
        "strh w7, [x8, #-2]!"
      ]
    },
    "push rax, rbx": {
      "ExpectedInstructionCount": 2,
      "Comment": [
        "Mergable 64-bit pushes"
      ],
      "x86Insts": [
        "push rax",
        "push rbx"
      ],
      "ExpectedArm64ASM": [
        "str x4, [x8, #-8]!",
        "str x7, [x8, #-8]!"
      ]
    },
    "adds xmm0, xmm1, xmm2": {
      "ExpectedInstructionCount": 4,
      "Comment": [
        "Redundant scalar adds that can get eliminated without AFP."
      ],
      "x86Insts": [
        "addss xmm0, xmm1",
        "addss xmm0, xmm2"
      ],
      "ExpectedArm64ASM": [
        "fadd s0, s16, s17",
        "mov v16.s[0], v0.s[0]",
        "fadd s0, s16, s18",
        "mov v16.s[0], v0.s[0]"
      ]
    },
    "positive movsb": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldrb w21, [x10]",
        "strb w21, [x11]",
        "add x10, x10, #0x1 (1)",
        "add x11, x11, #0x1 (1)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive movsw": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldrh w21, [x10]",
        "strh w21, [x11]",
        "add x10, x10, #0x2 (2)",
        "add x11, x11, #0x2 (2)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive movsd": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldr w21, [x10]",
        "str w21, [x11]",
        "add x10, x10, #0x4 (4)",
        "add x11, x11, #0x4 (4)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive movsq": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldr x21, [x10]",
        "str x21, [x11]",
        "add x10, x10, #0x8 (8)",
        "add x11, x11, #0x8 (8)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsb": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldrb w21, [x10]",
        "strb w21, [x11]",
        "sub x10, x10, #0x1 (1)",
        "sub x11, x11, #0x1 (1)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsw": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldrh w21, [x10]",
        "strh w21, [x11]",
        "sub x10, x10, #0x2 (2)",
        "sub x11, x11, #0x2 (2)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsd": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldr w21, [x10]",
        "str w21, [x11]",
        "sub x10, x10, #0x4 (4)",
        "sub x11, x11, #0x4 (4)",
        "strb w20, [x28, #986]"
      ]
    },
    "negative movsq": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldr x21, [x10]",
        "str x21, [x11]",
        "sub x10, x10, #0x8 (8)",
        "sub x11, x11, #0x8 (8)",
        "strb w20, [x28, #986]"
      ]
    },
    "positive rep movsb": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x14",
        "ldrb w3, [x2], #1",
        "strb w3, [x1], #1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2",
        "add x23, x1, x2",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "positive rep movsw": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x14",
        "ldrh w3, [x2], #2",
        "strh w3, [x1], #2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2, lsl #1",
        "add x23, x1, x2, lsl #1",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "positive rep movsd": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x14",
        "ldr w3, [x2], #4",
        "str w3, [x1], #4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2, lsl #2",
        "add x23, x1, x2, lsl #2",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "positive rep movsq": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x14",
        "ldr x3, [x2], #8",
        "str x3, [x1], #8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2, lsl #3",
        "add x23, x1, x2, lsl #3",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "negative rep movsb": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1f (31)",
        "sub x2, x2, #0x1f (31)",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1f (31)",
        "add x2, x2, #0x1f (31)",
        "ldrb w3, [x2], #-1",
        "strb w3, [x1], #-1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2",
        "sub x23, x1, x2",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep movsw": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1e (30)",
        "sub x2, x2, #0x1e (30)",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1e (30)",
        "add x2, x2, #0x1e (30)",
        "ldrh w3, [x2], #-2",
        "strh w3, [x1], #-2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2, lsl #1",
        "sub x23, x1, x2, lsl #1",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep movsd": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1c (28)",
        "sub x2, x2, #0x1c (28)",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1c (28)",
        "add x2, x2, #0x1c (28)",
        "ldr w3, [x2], #-4",
        "str w3, [x1], #-4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2, lsl #2",
        "sub x23, x1, x2, lsl #2",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep movsq": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x18 (24)",
        "sub x2, x2, #0x18 (24)",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x18 (24)",
        "add x2, x2, #0x18 (24)",
        "ldr x3, [x2], #-8",
        "str x3, [x1], #-8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2, lsl #3",
        "sub x23, x1, x2, lsl #3",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "positive rep stosb": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "uxtb w22, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.16b, w22",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x10",
        "strb w22, [x1], #1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "positive rep stosw": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "uxth w22, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.8h, w22",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x10",
        "strh w22, [x1], #2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5, lsl #1",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "positive rep stosd": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov w22, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.4s, w22",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x10",
        "str w22, [x1], #4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5, lsl #2",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "positive rep stosq": {
      "ExpectedInstructionCount": 29,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.2d, x4",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x10",
        "str x4, [x1], #8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5, lsl #3",
        "strb w21, [x28, #986]",
        "mov x5, x20"
      ]
    },
    "negative rep stosb": {
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "uxtb w21, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1f (31)",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.16b, w21",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1f (31)",
        "strb w21, [x1], #-1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosw": {
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "uxth w21, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1e (30)",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.8h, w21",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1e (30)",
        "strh w21, [x1], #-2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5, lsl #1",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosd": {
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov w21, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1c (28)",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.4s, w21",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1c (28)",
        "str w21, [x1], #-4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5, lsl #2",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "negative rep stosq": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x18 (24)",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.2d, x4",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x18 (24)",
        "str x4, [x1], #-8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5, lsl #3",
        "mov w5, #0x0",
        "strb w20, [x28, #986]"
      ]
    },
    "Sekiro spill block": {
      "ExpectedInstructionCount": 147,
      "Comment": [
        "This block of code came from the settings screen when it loaded",
        "It was originally at RIP: 0x14232cca0 and has been deobfuscated"
      ],
      "x86Insts": [
        "mov    QWORD [rsp+0x8],rcx",
        "push   rbx",
        "push   rbp",
        "push   rsi",
        "push   rdi",
        "push   r12",
        "push   r13",
        "push   r14",
        "push   r15",
        "sub    rsp,0x18",
        "mov    ecx,dword [rdx+0x24]",
        "mov    esi,dword [rdx]",
        "mov    ebp,dword [rdx+0x4]",
        "mov    r14d,dword [rdx+0x8]",
        "mov    r15d,dword [rdx+0xc]",
        "mov    r12d,dword [rdx+0x10]",
        "mov    r13d,dword [rdx+0x14]",
        "mov    r11d,dword [rdx+0x18]",
        "mov    ebx,dword [rdx+0x1c]",
        "mov    edi,dword [rdx+0x20]",
        "imul   eax,ecx,0x13",
        "mov    dword [rsp+0x68],ecx",
        "add    eax,0x1000000",
        "shr    eax,0x19",
        "add    eax,esi",
        "sar    eax,0x1a",
        "add    eax,ebp",
        "sar    eax,0x19",
        "add    eax,r14d",
        "sar    eax,0x1a",
        "add    eax,r15d",
        "sar    eax,0x19",
        "add    eax,r12d",
        "sar    eax,0x1a",
        "add    eax,r13d",
        "sar    eax,0x19",
        "add    eax,r11d",
        "sar    eax,0x1a",
        "add    eax,ebx",
        "sar    eax,0x19",
        "add    eax,edi",
        "sar    eax,0x1a",
        "add    eax,ecx",
        "sar    eax,0x19",
        "imul   eax,eax,0x13",
        "add    esi,eax",
        "mov    eax,esi",
        "sar    eax,0x1a",
        "add    ebp,eax",
        "shl    eax,0x1a",
        "sub    esi,eax",
        "mov    ecx,ebp",
        "mov    rax,qword [rsp+0x60]",
        "sar    ecx,0x19",
        "add    r14d,ecx",
        "shl    ecx,0x19",
        "mov    edx,r14d",
        "sub    ebp,ecx",
        "sar    edx,0x1a",
        "add    r15d,edx",
        "mov    dword [rax],esi",
        "mov    r8d,r15d",
        "shl    edx,0x1a",
        "sar    r8d,0x19",
        "sub    r14d,edx",
        "add    r12d,r8d",
        "mov    dword [rax+0x4],ebp",
        "mov    r9d,r12d",
        "shl    r8d,0x19",
        "sar    r9d,0x1a",
        "sub    r15d,r8d",
        "add    r13d,r9d",
        "mov    dword [rax+0x8],r14d",
        "shl    r9d,0x1a",
        "mov    r10d,r13d",
        "sar    r10d,0x19",
        "sub    r12d,r9d",
        "add    r11d,r10d",
        "mov    dword [rax+0xc],r15d",
        "mov    dword [rsp+0x70],r11d",
        "mov    rsi,rax",
        "sar    r11d,0x1a",
        "add    ebx,r11d",
        "mov    dword [rax+0x10],r12d",
        "mov    dword [rsp+0x78],ebx",
        "sar    ebx,0x19",
        "add    edi,ebx",
        "mov    dword [rsp],edi",
        "sar    edi,0x1a",
        "add    dword [rsp+0x68],edi",
        "shl    r10d,0x19",
        "mov    ecx,dword [rsp+0x68]",
        "sub    r13d,r10d",
        "mov    dword [rax+0x14],r13d",
        "mov    eax,dword [rsp+0x70]",
        "shl    r11d,0x1a",
        "sub    eax,r11d",
        "shl    ebx,0x19",
        "mov    dword [rsi+0x18],eax",
        "mov    eax,dword [rsp+0x78]",
        "sub    eax,ebx",
        "shl    edi,0x1a",
        "mov    dword [rsi+0x1c],eax",
        "mov    eax,dword [rsp]",
        "sub    eax,edi",
        "mov    dword [rsi+0x20],eax",
        "mov    eax,ecx",
        "and    eax,0xfe000000",
        "sub    ecx,eax",
        "mov    dword [rsi+0x24],ecx",
        "add    rsp,0x18",
        "pop    r15",
        "pop    r14",
        "pop    r13",
        "pop    r12",
        "pop    rdi",
        "pop    rsi",
        "pop    rbp",
        "pop    rbx"
      ],
      "ExpectedArm64ASM": [
        "str x5, [x8, #8]",
        "str x7, [x8, #-8]!",
        "str x9, [x8, #-8]!",
        "str x10, [x8, #-8]!",
        "str x11, [x8, #-8]!",
        "str x16, [x8, #-8]!",
        "str x17, [x8, #-8]!",
        "str x19, [x8, #-8]!",
        "str x29, [x8, #-8]!",
        "sub x8, x8, #0x18 (24)",
        "ldr w5, [x6, #36]",
        "ldr w10, [x6]",
        "ldr w9, [x6, #4]",
        "ldr w19, [x6, #8]",
        "ldr w29, [x6, #12]",
        "ldr w16, [x6, #16]",
        "ldr w17, [x6, #20]",
        "ldr w15, [x6, #24]",
        "ldr w7, [x6, #28]",
        "ldr w11, [x6, #32]",
        "mov w20, #0x13",
        "mul w4, w5, w20",
        "mov w21, w5",
        "str w21, [x8, #104]",
        "mov w21, #0x1000000",
        "add w4, w4, w21",
        "lsr w4, w4, #25",
        "add w4, w4, w10",
        "asr w4, w4, #26",
        "add w4, w4, w9",
        "asr w4, w4, #25",
        "add w4, w4, w19",
        "asr w4, w4, #26",
        "add w4, w4, w29",
        "asr w4, w4, #25",
        "add w4, w4, w16",
        "asr w4, w4, #26",
        "add w4, w4, w17",
        "asr w4, w4, #25",
        "add w4, w4, w15",
        "asr w4, w4, #26",
        "add w4, w4, w7",
        "asr w4, w4, #25",
        "add w4, w4, w11",
        "asr w4, w4, #26",
        "add w4, w4, w5",
        "asr w4, w4, #25",
        "mul w4, w4, w20",
        "add w10, w10, w4",
        "mov w4, w10",
        "asr w4, w4, #26",
        "add w9, w9, w4",
        "lsl w4, w4, #26",
        "sub w10, w10, w4",
        "mov w5, w9",
        "ldr x4, [x8, #96]",
        "asr w5, w5, #25",
        "add w19, w19, w5",
        "lsl w5, w5, #25",
        "mov w6, w19",
        "sub w9, w9, w5",
        "asr w6, w6, #26",
        "add w29, w29, w6",
        "mov w20, w10",
        "str w20, [x4]",
        "mov w12, w29",
        "lsl w6, w6, #26",
        "asr w12, w12, #25",
        "sub w19, w19, w6",
        "add w16, w16, w12",
        "mov w20, w9",
        "str w20, [x4, #4]",
        "mov w13, w16",
        "lsl w12, w12, #25",
        "asr w13, w13, #26",
        "sub w29, w29, w12",
        "add w17, w17, w13",
        "mov w20, w19",
        "str w20, [x4, #8]",
        "lsl w13, w13, #26",
        "mov w14, w17",
        "asr w14, w14, #25",
        "sub w16, w16, w13",
        "add w15, w15, w14",
        "mov w20, w29",
        "str w20, [x4, #12]",
        "mov w20, w15",
        "str w20, [x8, #112]",
        "mov x10, x4",
        "asr w15, w15, #26",
        "add w7, w7, w15",
        "mov w20, w16",
        "str w20, [x4, #16]",
        "mov w20, w7",
        "str w20, [x8, #120]",
        "asr w7, w7, #25",
        "add w11, w11, w7",
        "mov w20, w11",
        "str w20, [x8]",
        "asr w11, w11, #26",
        "ldr w20, [x8, #104]",
        "add w20, w20, w11",
        "str w20, [x8, #104]",
        "lsl w14, w14, #25",
        "ldr w5, [x8, #104]",
        "sub w17, w17, w14",
        "mov w20, w17",
        "str w20, [x4, #20]",
        "ldr w4, [x8, #112]",
        "lsl w15, w15, #26",
        "sub w4, w4, w15",
        "lsl w7, w7, #25",
        "mov w20, w4",
        "str w20, [x10, #24]",
        "ldr w4, [x8, #120]",
        "sub w4, w4, w7",
        "lsl w11, w11, #26",
        "mov w20, w4",
        "str w20, [x10, #28]",
        "ldr w4, [x8]",
        "sub w4, w4, w11",
        "mov w20, w4",
        "str w20, [x10, #32]",
        "mov w4, w5",
        "and w4, w4, #0xfe000000",
        "sub w5, w5, w4",
        "mov w20, w5",
        "str w20, [x10, #36]",
        "mvn w27, w8",
        "adds x26, x8, #0x18 (24)",
        "mov x8, x26",
        "ldr x29, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x19, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x17, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x16, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x11, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x10, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x9, [x8]",
        "add x8, x8, #0x8 (8)",
        "ldr x7, [x8]",
        "add x8, x8, #0x8 (8)"
      ]
    }
  }
}
