{
  "Features": {
    "Bitness": 64,
    "EnabledHostFeatures": [],
    "DisabledHostFeatures": [
      "SVE128",
      "SVE256",
      "RPRES",
      "AFP"
    ]
  },
  "Comment": [
    "These are instruction combinations that could be more optimal if FEX optimized for them"
  ],
  "Instructions": {
    "push ax, bx": {
      "ExpectedInstructionCount": 2,
      "Comment": [
        "Mergable 16-bit pushes. May or may not be an optimization."
      ],
      "x86Insts": [
        "push ax",
        "push bx"
      ],
      "ExpectedArm64ASM": [
        "strh w4, [x8, #-2]!",
        "strh w7, [x8, #-2]!"
      ]
    },
    "push rax, rbx": {
      "ExpectedInstructionCount": 2,
      "Comment": [
        "Mergable 64-bit pushes"
      ],
      "x86Insts": [
        "push rax",
        "push rbx"
      ],
      "ExpectedArm64ASM": [
        "str x4, [x8, #-8]!",
        "str x7, [x8, #-8]!"
      ]
    },
    "adds xmm0, xmm1, xmm2": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "Redundant scalar adds that can get eliminated without AFP."
      ],
      "x86Insts": [
        "addss xmm0, xmm1",
        "addss xmm0, xmm2"
      ],
      "ExpectedArm64ASM": [
        "mov v2.16b, v16.16b",
        "fadd s0, s16, s17",
        "mov v2.s[0], v0.s[0]",
        "mov v16.16b, v2.16b",
        "fadd s0, s2, s18",
        "mov v16.s[0], v0.s[0]"
      ]
    },
    "positive movsb": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldrb w21, [x10]",
        "strb w21, [x11]",
        "add x10, x10, #0x1 (1)",
        "add x11, x11, #0x1 (1)",
        "strb w20, [x28, #714]"
      ]
    },
    "positive movsw": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldrh w21, [x10]",
        "strh w21, [x11]",
        "add x10, x10, #0x2 (2)",
        "add x11, x11, #0x2 (2)",
        "strb w20, [x28, #714]"
      ]
    },
    "positive movsd": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldr w21, [x10]",
        "str w21, [x11]",
        "add x10, x10, #0x4 (4)",
        "add x11, x11, #0x4 (4)",
        "strb w20, [x28, #714]"
      ]
    },
    "positive movsq": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "movsq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x1",
        "ldr x21, [x10]",
        "str x21, [x11]",
        "add x10, x10, #0x8 (8)",
        "add x11, x11, #0x8 (8)",
        "strb w20, [x28, #714]"
      ]
    },
    "negative movsb": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldrb w21, [x10]",
        "strb w21, [x11]",
        "sub x10, x10, #0x1 (1)",
        "sub x11, x11, #0x1 (1)",
        "strb w20, [x28, #714]"
      ]
    },
    "negative movsw": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldrh w21, [x10]",
        "strh w21, [x11]",
        "sub x10, x10, #0x2 (2)",
        "sub x11, x11, #0x2 (2)",
        "strb w20, [x28, #714]"
      ]
    },
    "negative movsd": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldr w21, [x10]",
        "str w21, [x11]",
        "sub x10, x10, #0x4 (4)",
        "sub x11, x11, #0x4 (4)",
        "strb w20, [x28, #714]"
      ]
    },
    "negative movsq": {
      "ExpectedInstructionCount": 6,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "movsq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "ldr x21, [x10]",
        "str x21, [x11]",
        "sub x10, x10, #0x8 (8)",
        "sub x11, x11, #0x8 (8)",
        "strb w20, [x28, #714]"
      ]
    },
    "positive rep movsb": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x14",
        "ldrb w3, [x2], #1",
        "strb w3, [x1], #1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2",
        "add x23, x1, x2",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "positive rep movsw": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x14",
        "ldrh w3, [x2], #2",
        "strh w3, [x1], #2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2, lsl #1",
        "add x23, x1, x2, lsl #1",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "positive rep movsd": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x14",
        "ldr w3, [x2], #4",
        "str w3, [x1], #4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2, lsl #2",
        "add x23, x1, x2, lsl #2",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "positive rep movsq": {
      "ExpectedInstructionCount": 44,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep movsq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x78",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x54",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x34",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #32",
        "stp q0, q1, [x1], #32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x14",
        "ldr x3, [x2], #8",
        "str x3, [x1], #8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "add x22, x0, x2, lsl #3",
        "add x23, x1, x2, lsl #3",
        "mov x10, x23",
        "mov x11, x22",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "negative rep movsb": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1f (31)",
        "sub x2, x2, #0x1f (31)",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1f (31)",
        "add x2, x2, #0x1f (31)",
        "ldrb w3, [x2], #-1",
        "strb w3, [x1], #-1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2",
        "sub x23, x1, x2",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "negative rep movsw": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1e (30)",
        "sub x2, x2, #0x1e (30)",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1e (30)",
        "add x2, x2, #0x1e (30)",
        "ldrh w3, [x2], #-2",
        "strh w3, [x1], #-2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2, lsl #1",
        "sub x23, x1, x2, lsl #1",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "negative rep movsd": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x1c (28)",
        "sub x2, x2, #0x1c (28)",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x1c (28)",
        "add x2, x2, #0x1c (28)",
        "ldr w3, [x2], #-4",
        "str w3, [x1], #-4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2, lsl #2",
        "sub x23, x1, x2, lsl #2",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "negative rep movsq": {
      "ExpectedInstructionCount": 47,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep movsq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "mov x2, x10",
        "cbz x0, #+0x88",
        "sub x3, x1, x2",
        "tbz x3, #63, #+0x8",
        "neg x3, x3",
        "sub x3, x3, #0x20 (32)",
        "tbnz x3, #63, #+0x64",
        "sub x1, x1, #0x18 (24)",
        "sub x2, x2, #0x18 (24)",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x44",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x1c",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x14",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x3c",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "ldp q0, q1, [x2], #-32",
        "stp q0, q1, [x1], #-32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x1c",
        "add x1, x1, #0x18 (24)",
        "add x2, x2, #0x18 (24)",
        "ldr x3, [x2], #-8",
        "str x3, [x1], #-8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0xc",
        "mov x0, x11",
        "mov x1, x10",
        "mov x2, x5",
        "sub x22, x0, x2, lsl #3",
        "sub x23, x1, x2, lsl #3",
        "mov x10, x23",
        "mov x11, x22",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "positive rep stosb": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosb"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "uxtb w22, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.16b, w22",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x10",
        "strb w22, [x1], #1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "positive rep stosw": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosw"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "uxth w22, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.8h, w22",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x10",
        "strh w22, [x1], #2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5, lsl #1",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "positive rep stosd": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosd"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov w22, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.4s, w22",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x10",
        "str w22, [x1], #4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5, lsl #2",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "positive rep stosq": {
      "ExpectedInstructionCount": 29,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "cld",
        "rep stosq"
      ],
      "ExpectedArm64ASM": [
        "mov w20, #0x0",
        "mov w21, #0x1",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x58",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.2d, x4",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #32",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x2c",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x10",
        "str x4, [x1], #8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "add x11, x11, x5, lsl #3",
        "strb w21, [x28, #714]",
        "mov x5, x20"
      ]
    },
    "negative rep stosb": {
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosb"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "uxtb w21, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1f (31)",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.16b, w21",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x40 (64)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x40 (64)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x20 (32)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1f (31)",
        "strb w21, [x1], #-1",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "negative rep stosw": {
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosw"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "uxth w21, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1e (30)",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.8h, w21",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x20 (32)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x20 (32)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x10 (16)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1e (30)",
        "strh w21, [x1], #-2",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5, lsl #1",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "negative rep stosd": {
      "ExpectedInstructionCount": 31,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosd"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov w21, w4",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x1c (28)",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.4s, w21",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x10 (16)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x10 (16)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x8 (8)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x1c (28)",
        "str w21, [x1], #-4",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5, lsl #2",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "negative rep stosq": {
      "ExpectedInstructionCount": 30,
      "Comment": [
        "When direction flag is a compile time constant we can optimize",
        "loads and stores can turn in to post-increment when known"
      ],
      "x86Insts": [
        "std",
        "rep stosq"
      ],
      "ExpectedArm64ASM": [
        "mov x20, #0xffffffffffffffff",
        "mov x0, x5",
        "mov x1, x11",
        "cbz x0, #+0x60",
        "sub x1, x1, #0x18 (24)",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x3c",
        "dup v1.2d, x4",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x14",
        "stp q1, q1, [x1], #-32",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x8 (8)",
        "tbz x0, #63, #-0xc",
        "add x0, x0, #0x8 (8)",
        "cbz x0, #+0x30",
        "sub x0, x0, #0x4 (4)",
        "tbnz x0, #63, #+0x10",
        "stp q1, q1, [x1], #-32",
        "sub x0, x0, #0x4 (4)",
        "tbz x0, #63, #-0x8",
        "add x0, x0, #0x4 (4)",
        "cbz x0, #+0x14",
        "add x1, x1, #0x18 (24)",
        "str x4, [x1], #-8",
        "sub x0, x0, #0x1 (1)",
        "cbnz x0, #-0x8",
        "sub x11, x11, x5, lsl #3",
        "mov w5, #0x0",
        "strb w20, [x28, #714]"
      ]
    },
    "Sekiro spill block": {
      "ExpectedInstructionCount": 161,
      "Comment": [
        "This block of code came from the settings screen when it loaded",
        "It was originally at RIP: 0x14232cca0 and has been deobfuscated"
      ],
      "x86Insts": [
        "mov    QWORD [rsp+0x8],rcx",
        "push   rbx",
        "push   rbp",
        "push   rsi",
        "push   rdi",
        "push   r12",
        "push   r13",
        "push   r14",
        "push   r15",
        "sub    rsp,0x18",
        "mov    ecx,dword [rdx+0x24]",
        "mov    esi,dword [rdx]",
        "mov    ebp,dword [rdx+0x4]",
        "mov    r14d,dword [rdx+0x8]",
        "mov    r15d,dword [rdx+0xc]",
        "mov    r12d,dword [rdx+0x10]",
        "mov    r13d,dword [rdx+0x14]",
        "mov    r11d,dword [rdx+0x18]",
        "mov    ebx,dword [rdx+0x1c]",
        "mov    edi,dword [rdx+0x20]",
        "imul   eax,ecx,0x13",
        "mov    dword [rsp+0x68],ecx",
        "add    eax,0x1000000",
        "shr    eax,0x19",
        "add    eax,esi",
        "sar    eax,0x1a",
        "add    eax,ebp",
        "sar    eax,0x19",
        "add    eax,r14d",
        "sar    eax,0x1a",
        "add    eax,r15d",
        "sar    eax,0x19",
        "add    eax,r12d",
        "sar    eax,0x1a",
        "add    eax,r13d",
        "sar    eax,0x19",
        "add    eax,r11d",
        "sar    eax,0x1a",
        "add    eax,ebx",
        "sar    eax,0x19",
        "add    eax,edi",
        "sar    eax,0x1a",
        "add    eax,ecx",
        "sar    eax,0x19",
        "imul   eax,eax,0x13",
        "add    esi,eax",
        "mov    eax,esi",
        "sar    eax,0x1a",
        "add    ebp,eax",
        "shl    eax,0x1a",
        "sub    esi,eax",
        "mov    ecx,ebp",
        "mov    rax,qword [rsp+0x60]",
        "sar    ecx,0x19",
        "add    r14d,ecx",
        "shl    ecx,0x19",
        "mov    edx,r14d",
        "sub    ebp,ecx",
        "sar    edx,0x1a",
        "add    r15d,edx",
        "mov    dword [rax],esi",
        "mov    r8d,r15d",
        "shl    edx,0x1a",
        "sar    r8d,0x19",
        "sub    r14d,edx",
        "add    r12d,r8d",
        "mov    dword [rax+0x4],ebp",
        "mov    r9d,r12d",
        "shl    r8d,0x19",
        "sar    r9d,0x1a",
        "sub    r15d,r8d",
        "add    r13d,r9d",
        "mov    dword [rax+0x8],r14d",
        "shl    r9d,0x1a",
        "mov    r10d,r13d",
        "sar    r10d,0x19",
        "sub    r12d,r9d",
        "add    r11d,r10d",
        "mov    dword [rax+0xc],r15d",
        "mov    dword [rsp+0x70],r11d",
        "mov    rsi,rax",
        "sar    r11d,0x1a",
        "add    ebx,r11d",
        "mov    dword [rax+0x10],r12d",
        "mov    dword [rsp+0x78],ebx",
        "sar    ebx,0x19",
        "add    edi,ebx",
        "mov    dword [rsp],edi",
        "sar    edi,0x1a",
        "add    dword [rsp+0x68],edi",
        "shl    r10d,0x19",
        "mov    ecx,dword [rsp+0x68]",
        "sub    r13d,r10d",
        "mov    dword [rax+0x14],r13d",
        "mov    eax,dword [rsp+0x70]",
        "shl    r11d,0x1a",
        "sub    eax,r11d",
        "shl    ebx,0x19",
        "mov    dword [rsi+0x18],eax",
        "mov    eax,dword [rsp+0x78]",
        "sub    eax,ebx",
        "shl    edi,0x1a",
        "mov    dword [rsi+0x1c],eax",
        "mov    eax,dword [rsp]",
        "sub    eax,edi",
        "mov    dword [rsi+0x20],eax",
        "mov    eax,ecx",
        "and    eax,0xfe000000",
        "sub    ecx,eax",
        "mov    dword [rsi+0x24],ecx",
        "add    rsp,0x18",
        "pop    r15",
        "pop    r14",
        "pop    r13",
        "pop    r12",
        "pop    rdi",
        "pop    rsi",
        "pop    rbp",
        "pop    rbx"
      ],
      "ExpectedArm64ASM": [
        "sub sp, sp, #0xa0 (160)",
        "str x5, [x8, #8]",
        "str x7, [x8, #-8]!",
        "str x9, [x8, #-8]!",
        "str x10, [x8, #-8]!",
        "str x11, [x8, #-8]!",
        "str x16, [x8, #-8]!",
        "str x17, [x8, #-8]!",
        "str x19, [x8, #-8]!",
        "str x29, [x8, #-8]!",
        "sub x20, x8, #0x18 (24)",
        "ldr w21, [x6, #36]",
        "ldr w22, [x6]",
        "ldr w23, [x6, #4]",
        "ldr w24, [x6, #8]",
        "ldr w25, [x6, #12]",
        "ldr w30, [x6, #16]",
        "ldr w18, [x6, #20]",
        "str w18, [sp]",
        "ldr w18, [x6, #24]",
        "str w18, [sp, #32]",
        "ldr w18, [x6, #28]",
        "str w18, [sp, #64]",
        "ldr w18, [x6, #32]",
        "str w18, [sp, #96]",
        "mov w18, #0x13",
        "str w30, [sp, #128]",
        "mul w30, w21, w18",
        "str w21, [x20, #104]",
        "mov w18, #0x1000000",
        "add w30, w30, w18",
        "lsr w30, w30, #25",
        "add w30, w30, w22",
        "asr w30, w30, #26",
        "add w30, w30, w23",
        "asr w30, w30, #25",
        "add w30, w30, w24",
        "asr w30, w30, #26",
        "add w30, w30, w25",
        "asr w30, w30, #25",
        "ldr w18, [sp, #128]",
        "add w30, w30, w18",
        "asr w30, w30, #26",
        "ldr w18, [sp]",
        "add w30, w30, w18",
        "asr w30, w30, #25",
        "ldr w18, [sp, #32]",
        "add w30, w30, w18",
        "asr w30, w30, #26",
        "ldr w18, [sp, #64]",
        "add w30, w30, w18",
        "asr w30, w30, #25",
        "ldr w18, [sp, #96]",
        "add w30, w30, w18",
        "asr w30, w30, #26",
        "add w21, w30, w21",
        "asr w21, w21, #25",
        "mov w30, #0x13",
        "mul w21, w21, w30",
        "add w21, w22, w21",
        "mov w22, w21",
        "asr w22, w22, #26",
        "add w23, w23, w22",
        "lsl w22, w22, #26",
        "sub w21, w21, w22",
        "mov w22, w23",
        "ldr x30, [x20, #96]",
        "asr w22, w22, #25",
        "add w24, w24, w22",
        "lsl w22, w22, #25",
        "mov w18, w24",
        "sub w22, w23, w22",
        "asr w23, w18, #26",
        "add w25, w25, w23",
        "mov w21, w21",
        "str w21, [x30]",
        "mov w21, w25",
        "lsl w6, w23, #26",
        "asr w21, w21, #25",
        "sub w23, w24, w6",
        "ldr w24, [sp, #128]",
        "add w24, w24, w21",
        "mov w22, w22",
        "str w22, [x30, #4]",
        "mov w22, w24",
        "lsl w12, w21, #25",
        "asr w21, w22, #26",
        "sub w22, w25, w12",
        "ldr w25, [sp]",
        "add w25, w25, w21",
        "mov w23, w23",
        "str w23, [x30, #8]",
        "lsl w13, w21, #26",
        "mov w21, w25",
        "asr w21, w21, #25",
        "sub w23, w24, w13",
        "ldr w24, [sp, #32]",
        "add w24, w24, w21",
        "mov w22, w22",
        "str w22, [x30, #12]",
        "mov w22, w24",
        "str w22, [x20, #112]",
        "asr w22, w24, #26",
        "ldr w24, [sp, #64]",
        "add w24, w24, w22",
        "mov w23, w23",
        "str w23, [x30, #16]",
        "mov w23, w24",
        "str w23, [x20, #120]",
        "asr w23, w24, #25",
        "ldr w24, [sp, #96]",
        "add w24, w24, w23",
        "mov w18, w24",
        "str w18, [x20]",
        "asr w24, w24, #26",
        "ldr w18, [x20, #104]",
        "add w18, w18, w24",
        "str w18, [x20, #104]",
        "lsl w14, w21, #25",
        "ldr w21, [x20, #104]",
        "sub w25, w25, w14",
        "mov w25, w25",
        "str w25, [x30, #20]",
        "ldr w25, [x20, #112]",
        "lsl w15, w22, #26",
        "sub w22, w25, w15",
        "lsl w23, w23, #25",
        "mov w22, w22",
        "str w22, [x30, #24]",
        "ldr w22, [x20, #120]",
        "sub w22, w22, w23",
        "lsl w23, w24, #26",
        "mov w22, w22",
        "str w22, [x30, #28]",
        "ldr w22, [x20]",
        "sub w22, w22, w23",
        "mov w22, w22",
        "str w22, [x30, #32]",
        "and w4, w21, #0xfe000000",
        "sub w5, w21, w4",
        "mov w21, w5",
        "str w21, [x30, #36]",
        "mvn w27, w20",
        "adds x26, x20, #0x18 (24)",
        "ldr x29, [x26]",
        "add x20, x26, #0x8 (8)",
        "ldr x19, [x20]",
        "add x20, x20, #0x8 (8)",
        "ldr x17, [x20]",
        "add x20, x20, #0x8 (8)",
        "ldr x16, [x20]",
        "add x20, x20, #0x8 (8)",
        "ldr x11, [x20]",
        "add x20, x20, #0x8 (8)",
        "ldr x10, [x20]",
        "add x20, x20, #0x8 (8)",
        "ldr x9, [x20]",
        "add x20, x20, #0x8 (8)",
        "ldr x7, [x20]",
        "add x8, x20, #0x8 (8)",
        "add sp, sp, #0xa0 (160)"
      ]
    }
  }
}
